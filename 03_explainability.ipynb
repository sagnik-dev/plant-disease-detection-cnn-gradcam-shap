{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e520bce",
      "metadata": {
        "id": "6e520bce"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import shap\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import cv2\n",
        "\n",
        "# ------------------------------\n",
        "# 7a. Feature Maps (per Conv2D layer)\n",
        "# ------------------------------\n",
        "# Pick a random image from validation set\n",
        "batch_idx = random.randint(0, len(val_ds)-1)\n",
        "img, label = val_ds[batch_idx][0][0], val_ds[batch_idx][1][0]  # first image in batch\n",
        "img_input = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Detect all Conv2D layers automatically\n",
        "conv_layers = [layer for layer in model.layers if 'conv' in layer.name]\n",
        "\n",
        "for layer in conv_layers:\n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer.output)\n",
        "    activations = activation_model.predict(img_input)\n",
        "\n",
        "    # Plot first 6 filters\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(min(6, activations.shape[-1])):\n",
        "        plt.subplot(1, 6, i+1)\n",
        "        plt.imshow(activations[0, :, :, i], cmap='viridis')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"Feature Maps of {layer.name}\")\n",
        "    plt.show()\n",
        "\n",
        "# ------------------------------\n",
        "# 7b. SHAP (local interpretability)\n",
        "# ------------------------------\n",
        "sample_imgs, sample_labels = val_ds[0][:5]  # first 5 images from first batch\n",
        "explainer = shap.GradientExplainer(model, sample_imgs)\n",
        "shap_values = explainer.shap_values(sample_imgs)\n",
        "shap.image_plot(shap_values, sample_imgs)\n",
        "\n",
        "# Optional: LIME explanation for one image\n",
        "explainer_lime = lime_image.LimeImageExplainer()\n",
        "img_to_explain = val_ds[0][0][0]\n",
        "explanation = explainer_lime.explain_instance(\n",
        "    np.array(img_to_explain),\n",
        "    classifier_fn=lambda x: model.predict(x),\n",
        "    top_labels=1,\n",
        "    hide_color=0,\n",
        "    num_samples=1000\n",
        ")\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False\n",
        ")\n",
        "plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
        "plt.title(\"LIME Explanation\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------\n",
        "# 7c. Grad-CAM\n",
        "# ------------------------------\n",
        "# Automatically get the last Conv2D layer\n",
        "last_conv_layer = conv_layers[-1].name\n",
        "\n",
        "def get_gradcam(model, img_array, layer_name):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        loss = predictions[:, np.argmax(predictions[0])]\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    weights = tf.reduce_mean(grads[0], axis=(0, 1))\n",
        "\n",
        "    cam = np.zeros(conv_outputs.shape[:2], dtype=np.float32)\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * conv_outputs[:, :, i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cv2.resize(cam.numpy(), (img_width, img_height))\n",
        "    cam = cam - cam.min()\n",
        "    cam = cam / cam.max()\n",
        "    return cam\n",
        "\n",
        "cam = get_gradcam(model, np.expand_dims(img, axis=0), last_conv_layer)\n",
        "\n",
        "# Overlay heatmap on original image\n",
        "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "superimposed_img = heatmap * 0.4 + img\n",
        "plt.imshow(superimposed_img / 255)\n",
        "plt.title(\"Grad-CAM Overlay\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
